{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7727, -0.3389, -0.1840,  0.5645, -0.0775, -0.2983, -1.2093,  0.4237,\n",
      "          2.0949,  0.8848, -0.7230, -0.2230,  0.0488, -0.2833, -1.4652,  1.5824,\n",
      "         -1.2820,  0.5358, -1.1885, -0.1016],\n",
      "        [-0.6956,  1.3488,  0.7089, -0.1382,  0.6998,  0.2334,  0.5400, -0.1324,\n",
      "          0.8616,  0.0209, -0.2070,  0.2540, -1.8005,  0.1579, -0.8390, -0.0417,\n",
      "         -0.2288, -0.0323, -0.5640,  1.7304],\n",
      "        [ 0.0446, -1.3939,  0.9387, -0.8969,  1.5750,  1.2532,  0.7739, -1.4090,\n",
      "          1.5641,  0.7083, -0.9670,  1.0753, -0.9089,  0.6813,  3.0262, -0.2384,\n",
      "          0.4439,  0.1285, -0.6647, -1.1171],\n",
      "        [-0.6956,  1.3488,  0.7089, -0.1382,  0.6998,  0.2334,  0.5400, -0.1324,\n",
      "          0.8616,  0.0209, -0.2070,  0.2540, -1.8005,  0.1579, -0.8390, -0.0417,\n",
      "         -0.2288, -0.0323, -0.5640,  1.7304],\n",
      "        [-0.0880, -0.4981, -0.4940,  1.6404, -0.0312, -0.0764, -0.5956,  1.2367,\n",
      "         -0.9138,  0.7083,  0.2669, -1.4221,  2.2204, -0.0848, -1.3911,  0.4804,\n",
      "          1.5669, -0.7611,  0.4799,  1.5542]], grad_fn=<EmbeddingBackward>)\n",
      "torch.Size([5, 20])\n"
     ]
    }
   ],
   "source": [
    "emb = nn.Embedding(10000, 20, padding_idx=0)\n",
    "inp = torch.tensor([1, 2, 5, 2, 10], dtype=torch.int64)\n",
    "out = emb(inp)\n",
    "print(out)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pathlib\n",
    "import re\n",
    "\n",
    "remove_marks_regex = re.compile(\"[,\\.\\(\\)\\[\\]\\*:;]<.*?>\")\n",
    "shift_marks_regex = re.compile(\"([?!])\")\n",
    "\n",
    "def text2ids(text, vocab_dict):\n",
    "    text = remove_marks_regex.sub(\"\", text)\n",
    "    text = shift_marks_regex.sub(r\" \\1 \", text)\n",
    "    tokens = text.split()\n",
    "    return [vocab_dict.get(token, 0) for token in tokens]\n",
    "\n",
    "def list2tensor(token_idxes, max_len=100, padding=True):\n",
    "    if len(token_idxes) > max_len:\n",
    "        token_idxes = token_idxes[:max_len]\n",
    "    n_tokens = len(token_idxes)\n",
    "    if padding:\n",
    "        token_idxes = token_idxes + [0] * (max_len - len(token_idxes))\n",
    "    return torch.tensor(token_idxes, dtype=torch.int64), n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, dir_path, train=True, max_len=100, padding=True):\n",
    "        self.max_len = max_len\n",
    "        self.padding = padding\n",
    "        path = pathlib.Path(dir_path)\n",
    "        vocab_path = path.joinpath(\"imdb.vocab\")\n",
    "        \n",
    "        self.vocab_array = vocab_path.open().read().strip().splitlines()\n",
    "        self.vocab_dict = dict((w, i+1) for (i, w) in enumerate(self.vocab_array))\n",
    "        \n",
    "        if train:\n",
    "            target_path = path.joinpath(\"train\")\n",
    "        else:\n",
    "            target_path = path.joinpath(\"test\")\n",
    "        pos_files = sorted(glob.glob(str(target_path.joinpath(\"pos/*.txt\"))))\n",
    "        neg_files = sorted(glob.glob(str(target_path.joinpath(\"neg/*.txt\"))))\n",
    "        self.labeled_files = \\\n",
    "            list(zip([0]*len(neg_files), neg_files)) + \\\n",
    "            list(zip([1]*len(pos_files), pos_files))\n",
    "        \n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.vocab_array)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labeled_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label, f = self.labeled_files[idx]\n",
    "        data = open(f).read().lower()\n",
    "        data = text2ids(data, self.vocab_dict)\n",
    "        data, n_tokens = list2tensor(data, self.max_len, self.padding)\n",
    "        return data, label, n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = IMDBDataset(\"./data/aclImdb/\")\n",
    "test_data = IMDBDataset(\"./data/aclImdb/\", train=False)\n",
    "train_loader = DataLoader(train_data, batch_size=32,\n",
    "                          shuffle=True, num_workers=8)\n",
    "test_loader = DataLoader(test_data, batch_size=32,\n",
    "                         shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceTaggingNet(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim=50, hidden_size=50,\n",
    "                 num_layers=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_embeddings, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size,\n",
    "                            num_layers, batch_first=True, dropout=dropout)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x, h0=None, l=None):\n",
    "        x = self.emb(x)\n",
    "        x, h = self.lstm(x, h0)\n",
    "        if l is not None:\n",
    "            x = x[list(range(len(x))), l-1, :]\n",
    "        else:\n",
    "            x = x[:, -1, :]\n",
    "        x = self.linear(x)\n",
    "        x = x.squeeze()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(net, data_loader, device=\"cpu\"):\n",
    "    net.eval()\n",
    "    ys = []\n",
    "    ypreds = []\n",
    "    for x, y, l in data_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        l = l.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_pred = net(x, l=l)\n",
    "            y_pred = (y_pred > 0).long()\n",
    "            ys.append(y)\n",
    "            ypreds.append(y_pred)\n",
    "    ys = torch.cat(ys)\n",
    "    ypreds = torch.cat(ypreds)\n",
    "    acc = (ys == ypreds).float().sum() / len(ys)\n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:09<00:00, 80.95it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoc: 0\tmean(losses): 0.676\ttrain_acc: 0.629\tval_acc: 0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:09<00:00, 83.73it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoc: 1\tmean(losses): 0.603\ttrain_acc: 0.742\tval_acc: 0.698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:09<00:00, 83.87it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoc: 2\tmean(losses): 0.498\ttrain_acc: 0.815\tval_acc: 0.747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:09<00:00, 84.15it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoc: 3\tmean(losses): 0.410\ttrain_acc: 0.861\tval_acc: 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:09<00:00, 84.18it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoc: 4\tmean(losses): 0.381\ttrain_acc: 0.847\tval_acc: 0.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:09<00:00, 83.54it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoc: 5\tmean(losses): 0.325\ttrain_acc: 0.891\tval_acc: 0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:09<00:00, 84.46it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoc: 6\tmean(losses): 0.280\ttrain_acc: 0.917\tval_acc: 0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:09<00:00, 83.70it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoc: 7\tmean(losses): 0.234\ttrain_acc: 0.937\tval_acc: 0.780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:09<00:00, 84.21it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoc: 8\tmean(losses): 0.193\ttrain_acc: 0.946\tval_acc: 0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:09<00:00, 83.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoc: 9\tmean(losses): 0.162\ttrain_acc: 0.963\tval_acc: 0.770\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "net = SequenceTaggingNet(train_data.vocab_size+1, num_layers=2)\n",
    "net.to(\"cuda:0\")\n",
    "opt = optim.Adam(net.parameters())\n",
    "loss_f = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoc in range(10):\n",
    "    losses = []\n",
    "    net.train()\n",
    "    for x, y, l in tqdm.tqdm(train_loader):\n",
    "        x = x.to(\"cuda:0\")\n",
    "        y = y.to(\"cuda:0\")\n",
    "        l = l.to(\"cuda:0\")\n",
    "        y_pred = net(x, l=l)\n",
    "        loss = loss_f(y_pred, y.float())\n",
    "        net.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        losses.append(loss.item())\n",
    "    train_acc = eval_net(net, train_loader, \"cuda:0\")\n",
    "    val_acc = eval_net(net, test_loader, \"cuda:0\")\n",
    "    print(\"epoc: {}\\tmean(losses): {:.3f}\\ttrain_acc: {:.3f}\\tval_acc: {:.3f}\".format(\n",
    "    epoc, mean(losses), train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93132 0.394\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "train_X, train_y = load_svmlight_file(\"./data/aclImdb/train/labeledBow.feat\")\n",
    "test_X, test_y = load_svmlight_file(\"./data/aclImdb/test/labeledBow.feat\")\n",
    "\n",
    "model = LogisticRegression(C=0.1, max_iter=5000)\n",
    "model.fit(train_X[:, :test_X.shape[1]], train_y[:test_y.shape[0]])\n",
    "train_score = model.score(train_X[:, :test_X.shape[1]], train_y[:test_y.shape[0]])\n",
    "test_score = model.score(test_X, test_y)\n",
    "print(train_score, test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceTaggingNet2(SequenceTaggingNet):\n",
    "    def forward(self, x, h0=None, l=None):\n",
    "        x = self.emb(x)\n",
    "        if l is not None:\n",
    "            x = nn.utils.rnn.pack_padded_sequence(x, l, batch_first=True)\n",
    "        x, h = self.lstm(x, h0)\n",
    "        if l is not None:\n",
    "            hidden_state, cell_state = h\n",
    "            x = hidden_state[-1]\n",
    "        else:\n",
    "            x = x[:, -1, :]\n",
    "        \n",
    "        x = self.linear(x).squeeze()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net2(net, data_loader, device=\"cpu\"):\n",
    "    net.eval()\n",
    "    ys = []\n",
    "    ypreds = []\n",
    "    for x, y, l in data_loader:\n",
    "        l, sort_idx = torch.sort(l, descending=True)\n",
    "        x = x[sort_idx]\n",
    "        y = y[sort_idx]\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        l = l.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_pred = net(x, l=l)\n",
    "            y_pred = (y_pred > 0).long()\n",
    "            ys.append(y)\n",
    "            ypreds.append(y_pred)\n",
    "    ys = torch.cat(ys)\n",
    "    ypreds = torch.cat(ypreds)\n",
    "    acc = (ys == ypreds).float().sum() / len(ys)\n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:10<00:00, 72.54it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\tmean(losses): 0.688\ttrain_acc: 0.542\tval_acc: 0.543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:10<00:00, 71.96it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\tmean(losses): 0.681\ttrain_acc: 0.592\tval_acc: 0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:10<00:00, 72.31it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2\tmean(losses): 0.660\ttrain_acc: 0.690\tval_acc: 0.650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:10<00:00, 71.67it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3\tmean(losses): 0.575\ttrain_acc: 0.732\tval_acc: 0.676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:10<00:00, 72.04it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4\tmean(losses): 0.487\ttrain_acc: 0.824\tval_acc: 0.739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:10<00:00, 72.97it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\tmean(losses): 0.422\ttrain_acc: 0.861\tval_acc: 0.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:10<00:00, 72.92it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6\tmean(losses): 0.351\ttrain_acc: 0.890\tval_acc: 0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:10<00:00, 73.99it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7\tmean(losses): 0.296\ttrain_acc: 0.916\tval_acc: 0.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:10<00:00, 73.17it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8\tmean(losses): 0.249\ttrain_acc: 0.921\tval_acc: 0.760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:10<00:00, 72.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9\tmean(losses): 0.205\ttrain_acc: 0.952\tval_acc: 0.767\n"
     ]
    }
   ],
   "source": [
    "net = SequenceTaggingNet2(train_data.vocab_size+1, num_layers=2)\n",
    "net.to(\"cuda:0\")\n",
    "opt = optim.Adam(net.parameters())\n",
    "loss_f = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    losses = []\n",
    "    net.train()\n",
    "    for x, y, l in tqdm.tqdm(train_loader):\n",
    "        l, sort_idx = torch.sort(l, descending=True)\n",
    "        x = x[sort_idx]\n",
    "        y = y[sort_idx]\n",
    "        \n",
    "        x = x.to(\"cuda:0\")\n",
    "        y = y.to(\"cuda:0\")\n",
    "        l = l.to(\"cuda:0\")\n",
    "        \n",
    "        y_pred = net(x, l=l)\n",
    "        loss = loss_f(y_pred, y.float())\n",
    "        net.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        losses.append(loss.item())\n",
    "    train_acc = eval_net2(net, train_loader, \"cuda:0\")\n",
    "    val_acc = eval_net2(net, test_loader, \"cuda:0\")\n",
    "    print(\"epoch: {}\\tmean(losses): {:.3f}\\ttrain_acc: {:.3f}\\tval_acc: {:.3f}\".format(\n",
    "    epoch, mean(losses), train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文章生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\u000b",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "all_chars = string.printable\n",
    "print(all_chars)\n",
    "vocab_size = len(all_chars)\n",
    "vocab_dict = dict((c, i) for i, c in enumerate(all_chars))\n",
    "\n",
    "def str2ints(s, vocab_dict):\n",
    "    return [vocab_dict[c] for c in s]\n",
    "\n",
    "def ints2str(x, vocab_array):\n",
    "    return \"\".join([vocab_array[i] for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShakespeareDataset(Dataset):\n",
    "    def __init__(self, path, chunk_size=200):\n",
    "        data = str2ints(open(path).read().strip(), vocab_dict)\n",
    "        data = torch.tensor(data, dtype=torch.int64).split(chunk_size)\n",
    "        if len(data[-1]) < chunk_size:\n",
    "            data = data[:-1]\n",
    "        self.data = data\n",
    "        self.n_chunks = len(self.data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_chunks\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ShakespeareDataset(\"./data/tinyshakespeare.txt\")\n",
    "loader = DataLoader(ds, batch_size=32, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceGenerationNet(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim=50, hidden_size=50,\n",
    "                 num_layers=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers,\n",
    "                            batch_first=True, dropout=dropout)\n",
    "        self.linear = nn.Linear(hidden_size, num_embeddings)\n",
    "        \n",
    "    def forward(self, x, h0=None):\n",
    "        x = self.emb(x)\n",
    "        x, h = self.lstm(x, h0)\n",
    "        x = self.linear(x)\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq(net, start_phrase=\"The King said \", length=200,\n",
    "                 temperature=0.8, device=\"cpu\"):\n",
    "    net.eval()\n",
    "    result = []\n",
    "    \n",
    "    start_tensor = torch.tensor(str2ints(start_phrase, vocab_dict),\n",
    "                                dtype=torch.int64).to(device)\n",
    "    x0 = start_tensor.unsqueeze(0)\n",
    "    o, h = net(x0)\n",
    "    out_dist = o[:, -1].view(-1).exp()\n",
    "    top_i = torch.multinomial(out_dist, 1)[0]\n",
    "    result.append(top_i)\n",
    "    \n",
    "    for i in range(length):\n",
    "        inp = torch.tensor([[top_i]], dtype=torch.int64)\n",
    "        inp = inp.to(device)\n",
    "        o, h = net(inp, h)\n",
    "        out_dist = o.view(-1).exp()\n",
    "        top_i = torch.multinomial(out_dist, 1)[0]\n",
    "        result.append(top_i)\n",
    "        \n",
    "    return start_phrase + ints2str(result, all_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "s = numpy.array([[1, 2], [3, 4]])\n",
    "print(s[:, -1].reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 60.23it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\tmean(losses):3.490\n",
      "The King said :de' mwTliain\n",
      "nITp hciorfni\n",
      "a`nhWbtOiRedtouc ,lrn Whbe:htao2metfCnn htsaboh:;rl  hm,'wh,s abAd n\n",
      " i ;Hbe dbdo  I ,lahnhetteeh+o o, adrmbs leh Peao:loekRos tpsoetHLAroR\n",
      "a fLypedIfieked\n",
      "a ioIdIiiOto ,aro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:03<00:00, 57.01it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1\tmean(losses):3.225\n",
      "The King said t, taer admn ch t\n",
      "recmngreit! erordraeim g hko sbod Lmouewh,f nto tsno mEfg oy nsy hi.oeoaw ed\n",
      "Mi i\n",
      "Ae iaLb li, yb wCshde ahwi sccyshhscyalop esawkemo rotwh\n",
      ". lo  hsl yu t d?ydturMplayr\n",
      "e IIt  maesfon \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:03<00:00, 55.20it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2\tmean(losses):2.817\n",
      "The King said fdl. it at tuy ixh bt erutorl mhnaldy Bon thOise\n",
      "\n",
      "MI&KOYUOP\n",
      "AOESEW:\n",
      "(asl Nhiort anl maons whoe eos anilr iriuir bidnpyirdr; oa,,r tisn,\n",
      "Tiou stnanesls.\n",
      "\n",
      ": aws agideso ft Slhhn tooe seg! msfeld mritd gv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 63.27it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3\tmean(losses):2.525\n",
      "The King said alt\n",
      ":\n",
      "Anst core hir to lam, in on to maes fis adon, awlrff te by I lifmgiglrre,,\n",
      "Mourh cmie\n",
      "Whinm be le ades I puourwendh\n",
      "I done coas hiclinerifu shamin se, tetell mo?\n",
      "\n",
      "COve yor fat the,\n",
      " Iens chanr th\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 62.51it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4\tmean(losses):2.377\n",
      "The King said hy whjy thet wis agend; cimasheed Sorle arle bi!\n",
      "3ate be to the tive thee to;\n",
      "Ecfos id.\n",
      "iran, mam socut wore heatfr ame ace tmewr\n",
      "oicasd chany oaet thke rith soun:\n",
      "Wy hougln: yEminco?\n",
      "Thaam\n",
      "Bhave chive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 59.48it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5\tmean(losses):2.292\n",
      "The King said ward han,\n",
      "And unnetass\n",
      "Thetae enkinchrerd blees Rothend tereacilchad,\n",
      "Sotid.\n",
      "\n",
      "DUMINGS:\n",
      "Irthe seel ad than not gipde:\n",
      "MGoun lench yog ber\n",
      "Tese tho siy faas wowt,, havet tinot bonneand,\n",
      "An the les id Pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 60.50it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6\tmean(losses):2.228\n",
      "The King said forlirlaip wot mround Fout-toreom\n",
      "Thke chicle fod,\n",
      "'ime nicfems thevt teabbut,\n",
      "Iu and,\n",
      "engri'd Got thtife,\n",
      "Ansls tinves of promind ba marrhaos saaritwewthe the hath futy.\n",
      "Lat mine, math sard mee he the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 62.37it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7\tmean(losses):2.173\n",
      "The King said kopchers not swade pestenk, freculy a yaat, whour thitiy thoo!\n",
      "the thir, igart wulc,\n",
      "To a withey thou:\n",
      "Nou-s\n",
      "'er sroolld a theese or mapaulches thop inge he the dleestare!\n",
      "O I fut ad arghlofsru nelleal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:03<00:00, 57.97it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8\tmean(losses):2.124\n",
      "The King said hagh of Reestaly thee hir hid a, hitlommhy bu'd stue, alk a angt throm hundy thou to linty then I hout im wap, whors, frad! Agt'ch.\n",
      "/wet, lileoned the in,\n",
      "I be thou, heuch betertor tucpnof;\n",
      "dod sore,\n",
      "A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 58.62it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9\tmean(losses):2.083\n",
      "The King said ite wim begtealter, war, fo titarteascernd the filling, fo sto to cnourer,\n",
      "There? thiid gowtllore deringury wouth\n",
      "eres' vatace 3Bhobly buth alk, of thoe all,\n",
      "I wici-till all? Felut\n",
      "Freerse so he cipend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:03<00:00, 58.31it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10\tmean(losses):2.049\n",
      "The King said the stloud:\n",
      "And shorthlee se cardems:\n",
      "incostiag ure,\n",
      "Burt.\n",
      "\n",
      "COLANGUES:\n",
      "Bothing\n",
      "theit me steen foly hy burs and ticfoys will.\n",
      "\n",
      "I:\n",
      "Bowe lering, by Trouvour's on dile goaod\n",
      "Thince my nasty we'd lors soaru\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 59.78it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11\tmean(losses):2.021\n",
      "The King said it the skakhend the wheiliy she fay, I my mam,\n",
      "Buts, tey is thach hen tirke,\n",
      "Our the, of hy he drothars, ort not ix Ore cunad suach to not with thant not you and butwac hiturict make your fon toBcroon\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 58.92it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12\tmean(losses):1.996\n",
      "The King said the Rerisse-ne perod tell in shing by wirdos guos, at not fake! to'mere Frold hove inge, Fost here coneritpres-\n",
      "\n",
      "PLOBENTIA:\n",
      "So oice\n",
      "Tfor it I legiend.\n",
      "\n",
      "IUKEN ERFIRA:\n",
      "I he for to not and in y bath.\n",
      "\n",
      "LOU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 60.70it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13\tmean(losses):1.974\n",
      "The King said Privedtickmezets a wory lecherst heart huner's my thee balle: I darlin bires, so I ar's dands,\n",
      "And nelia pribe brebent will lal!\n",
      "Wide cunchs!'\n",
      "Rattent siad will ut gigattelt\n",
      "the spach Appyge daingald, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:03<00:00, 57.53it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14\tmean(losses):1.952\n",
      "The King said men have to you his kavimy will and harly Maranridess. telk of who wurse thnows you to peinding nor with to beim\n",
      "ese a ruth themstelt; cordarts,\n",
      "Rith he ashousour, and for frar be mime, stleims and sha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 58.95it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15\tmean(losses):1.930\n",
      "The King said ud.\n",
      "Ard did's as be bladed\n",
      "Thage cosk withperows shals deaphore nod\n",
      "Wo mes hing the storling,\n",
      "Did had thee bleer.\n",
      "\n",
      "LEONTESS:\n",
      "To go bo-wipe of why tay you heoy sinknn\n",
      "to thou so no whal the bede,\n",
      "And na\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:03<00:00, 57.81it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16\tmean(losses):1.910\n",
      "The King said wort me thathc manry.\n",
      "\n",
      "CYORETCY:\n",
      "Nell stat, and heaegour to haow and witip, will five, be lired one so eljropielks:\n",
      "With youf hon, you that her fain to fritiegen are maruty: my gands,--wors accost sard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 59.18it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17\tmean(losses):1.894\n",
      "The King said thuft elver not mere.\n",
      "\n",
      "WAMYINIU:\n",
      "Toakes that knowe if what cather perange.\n",
      "\n",
      "TROMICOLIAR:\n",
      "Whit of by Folled's, nos not with. O redast, of mes acerou!\n",
      "\n",
      "PLAMIAS:\n",
      "O molch well thou thrights hatayen mone re\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 59.13it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18\tmean(losses):1.878\n",
      "The King said Haaded as sow; my the somfe.\n",
      "\n",
      "JOMTENETIAT:\n",
      "No, then this hiwt\n",
      "the kifince there thou a gone in sot.\n",
      "\n",
      "Fir rod:\n",
      "A whas to sice for, home ackmut, ceak, alllings 'wide.\n",
      "\n",
      "Sillning\n",
      "\n",
      "TEUNE:\n",
      "Now your it me of \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 60.25it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19\tmean(losses):1.865\n",
      "The King said for tirke,\n",
      "Then ear, and that; I syraed is's sfatksbel freants of fortion, hast they vave me all.\n",
      "\n",
      "BALFCANT:\n",
      "God thry eak sand to there wost evint---withto duds gosbendie.\n",
      "\n",
      "AUPESTIP:\n",
      "Ay man not is'ing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 63.02it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20\tmean(losses):1.854\n",
      "The King said of combrecs'se sood\n",
      "Whie pyeluve uney; whoth porse, Kall sives: I ga; speir preed you landiod\n",
      "hir popn that howe her home, swey waindly as is herp thy prvarkt.\n",
      "\n",
      "KING ET:\n",
      "Id canafeivever farse;\n",
      "You, thy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 59.71it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21\tmean(losses):1.842\n",
      "The King said lirching shatled were at,\n",
      "Lot a sach your vevere hid of whres.\n",
      "\n",
      "PETUTEBBOUPE:\n",
      "Whipce the shome Gearlys goy reat?\n",
      "\n",
      "ROMHUKH:\n",
      "Hard'd sterrious insh your douting\n",
      "Ulloy wear you karent a what her misall age\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 60.55it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22\tmean(losses):1.831\n",
      "The King said ruspers; be lie your you, say;\n",
      "hir preanpoming owes, the lain gour?\n",
      "\n",
      "QUPEO:\n",
      "To wichy Creake, lors matiess, the sore inour:\n",
      "Why he he gruch my word thes and best your mishich\n",
      "It, igh! and'lling riess il\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:03<00:00, 56.97it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23\tmean(losses):1.822\n",
      "The King said and troier it as wates,\n",
      "With I cort's tese is connowd.\n",
      "\n",
      "ENRANT:\n",
      "I hast fisure, not as some.\n",
      "\n",
      "First ewsen:\n",
      "Your Rome think\n",
      "Withimass, and to what woltome liusens art.\n",
      "\n",
      "BRINCET\n",
      "\n",
      "IZENEK:\n",
      "She krop praief, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 61.15it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24\tmean(losses):1.813\n",
      "The King said are slonnenca our worldese\n",
      "The fispury's, I know,: I coanlnoneng\n",
      "For dive he shy 'hiss staughtil whigh therethice and fead.\n",
      "He camLing no singelf: not are, cholid;\n",
      "Droovous, blick, and what rewsters hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 61.13it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25\tmean(losses):1.805\n",
      "The King said yourerthand tepter.\n",
      "\n",
      "LUCIO:\n",
      "'I own do is, so his, and your wards,\n",
      "Ewpornay, decuttle hampelcied!\n",
      "\n",
      "JULIET:\n",
      "\n",
      "RADIO:\n",
      "O; sad spatis anitur imon encere firlaliave,\n",
      "Whose, mesean: a kone:\n",
      "If madione montio d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 59.03it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26\tmean(losses):1.798\n",
      "The King said bly, had tust but:\n",
      "God's not weres that to untrue detclame', his depied, anly,\n",
      "Beal confired he lids, yours, be athill I argha:\n",
      "he this my wall be offy me the deif.\n",
      "\n",
      "RICHESS\n",
      "\n",
      "PuonneschtAll on you\n",
      "Hould\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 58.80it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27\tmean(losses):1.789\n",
      "The King said shall he have ible\n",
      "For terury with that furrot the piluck;\n",
      "That as desall\n",
      "The pay thou in shlaised. Where thear\n",
      "If and this the sears I day to so thes; to bees,\n",
      "As seen for love with offment my wroy ha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:03<00:00, 58.30it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28\tmean(losses):1.781\n",
      "The King said of stry then, no willfus,\n",
      "Nuvish her call lickcant ender,\n",
      "Whis is the gother sopd the paster,\n",
      "On, Calneds, nobly was the and forguar the hare.\n",
      "\n",
      "VOUTBET:\n",
      "There Cmasse tell his heath, felling's\n",
      "Transs ha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 58.72it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29\tmean(losses):1.775\n",
      "The King said dlining to the peyrard all\n",
      "Sishialy dock and gising abodey there dight\n",
      "mish in it's is a fhatter!\n",
      "\n",
      "COMILANDZHARI:\n",
      "Now Epwicle insting it Bpay dispersin.\n",
      "\n",
      "RALINS:\n",
      "And of!\n",
      "to, no perore cleish the qounke\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 60.55it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30\tmean(losses):1.768\n",
      "The King said the braidher that so.\n",
      "\n",
      "CSAMENCO:\n",
      "My\n",
      "Im you says? goung anings baves cather,\n",
      "He woulder nef instay not it it the rancose:\n",
      "I, Rastharks, fhal a kire ut that thus eeps,\n",
      "And Bhenmy for upent with's did. Th\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 62.78it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31\tmean(losses):1.761\n",
      "The King said Dand rike,\n",
      "This mishated my means so a rainer;\n",
      "That the live, yours or thy like thou: atfied scones.\n",
      "\n",
      "TLANCE:\n",
      "I grom the ficcee, brys\n",
      "by a firrut lick wall in a throp doye\n",
      "If I envivign my burd\n",
      "cerchio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 64.43it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32\tmean(losses):1.755\n",
      "The King said that, you knong,\n",
      "My voak. Now-sear than here, and dedsistein;\n",
      "It chattion House have-batter's, a\n",
      "he the casilly shamr.\n",
      "\n",
      "CILIUBS:\n",
      "Qish sin word the moles once thou wisulate told.\n",
      "\n",
      "AUTOLYCE:\n",
      "What I know \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 58.72it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33\tmean(losses):1.749\n",
      "The King said shave on will:\n",
      "Let a lustress my near?\n",
      "\n",
      "GOcEONZALE:\n",
      "Her farell vift is and words be tone hath inks notes,\n",
      "Wruch of hese 'wave of that unthak's are light that.\n",
      "\n",
      "LADRY BIO:\n",
      "Yeir thee the maunote wordiadh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:03<00:00, 55.58it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34\tmean(losses):1.742\n",
      "The King said your the are epless!\n",
      "That Evire brechone we sin thich it in loml daith,\n",
      "The gone ries reer cacked haf in the comer of I\n",
      "Ast tish range, there micules a reveqireld much.\n",
      "\n",
      "HARTINGO:\n",
      "Ega, my and his that \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:03<00:00, 58.02it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35\tmean(losses):1.737\n",
      "The King said on thy nabrought thou in shows\n",
      "Out disparin the and to pentreating pentered us.\n",
      "\n",
      "POMPEY:\n",
      "Shall for Gecough of onour Jone,\n",
      "And ay than yoarfore be thou more:\n",
      "An be to Rolwry, the paid great, that beap e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 61.95it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36\tmean(losses):1.731\n",
      "The King said the lize. Yet Jento eets, priet;\n",
      "With of is dich les, he loves of you hasbrank\n",
      "O king us doth lerness my for her inting.\n",
      "\n",
      "JORY:\n",
      "I'll bear shore his Lords his slembrom to pleent\n",
      "A baisheb be sulden no s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 60.92it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37\tmean(losses):1.726\n",
      "The King said presise:\n",
      "I'll that siny you shick tither make man\n",
      "That came evidtles Rikele and Wolday'sw molef-more\n",
      "Fria canciest with she comect'd saul?\n",
      "\n",
      "QUEEN ELIZABESTW:\n",
      "It hold and I cumeing, no must ip did,\n",
      "Aada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 60.73it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38\tmean(losses):1.721\n",
      "The King said be a malf flangets more\n",
      "by seel the pleadlentieiss the will, thy chinger.\n",
      "\n",
      "Sirwron:\n",
      "Whefely whrawta, not is sice;\n",
      "To-rong, my good my not marry welln their wad,\n",
      "Aidss afcurea; for himtail shonest queen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 58.48it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39\tmean(losses):1.717\n",
      "The King said did hear is losour see.\n",
      "\n",
      "GLOUCESTER:\n",
      "Now nor the to honour I all: the be in that you this to his\n",
      "Illy let adey my prarjoit, pofer we the\n",
      "I comancion's nofence mine no makself,\n",
      "Baly I hasseings ustiage,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 59.61it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40\tmean(losses):1.711\n",
      "The King said when Jaice add ip the\n",
      "Friendous life poor you sporkble ever uping\n",
      "That you his py had a steze on ward.\n",
      "\n",
      "Pwond:\n",
      "But you see, what way grow by the king.\n",
      "\n",
      "Weren:\n",
      "How, deestly that we was wind your more an\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 58.53it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41\tmean(losses):1.708\n",
      "The King said there or the look show, and, can\n",
      "To is I whill dight lived in to stoplicord you hother,\n",
      "And dasemortsed it that love me! eld.\n",
      "\n",
      "PETRUCHIO:\n",
      "Kill the parries of vause; king firs to be\n",
      "This will that Marem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 59.73it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42\tmean(losses):1.704\n",
      "The King said barible hath pumes to deed her me.\n",
      "\n",
      "ALBOGKE:\n",
      "Sand aming; which mean, and begent line pleated,\n",
      "\n",
      "KING RICHARD III:\n",
      "Do beal not faossed when did did his green.\n",
      "Way you cal upon is a gachich be hang\n",
      "Dand a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 62.02it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43\tmean(losses):1.700\n",
      "The King said a goodnd of 'tud then.\n",
      "\n",
      "TERKEN:\n",
      "Frant all tall shand of find my friends, that clows\n",
      "Come time chance bestell from alcels give poor upbook.\n",
      "\n",
      "CAPRLOLINS:\n",
      "May clows, father are pranganet, plidigpevil,\n",
      "At,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 59.58it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44\tmean(losses):1.696\n",
      "The King said thy crosted fly it passiis.\n",
      "\n",
      "YORK:\n",
      "Hin all to tims his king badot: take mister that creef,\n",
      "Thind your dost man when that I have as blomry:\n",
      "And in thou that men, he cloise craee as, she nother\n",
      "For a gre\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 62.05it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45\tmean(losses):1.693\n",
      "The King said the from. Whrichle his age,\n",
      "Day dear come with not our will fioder beast\n",
      "The tright all whithal kils,\n",
      "The sorry world for our austy, Maredhe'd\n",
      "Mighnd is their weave Engech shord, bids what\n",
      "not this my \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 60.00it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46\tmean(losses):1.689\n",
      "The King said on are, stonemy loonted\n",
      "Min to she reber love to panous, I duke,\n",
      "This will aticers tooth thuch to verrelice and heaved:\n",
      "I was a not of it my minesth of I bond\n",
      "of caught.\n",
      "\n",
      "First Srovenger:\n",
      "Aseer Larecio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 59.03it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47\tmean(losses):1.686\n",
      "The King said and in vieple, and the'chelds;\n",
      "Where dean his pariss talk the gave but to cheace there\n",
      "what up with enteoune parwar Lord lick Pay\n",
      "Even so ip: I heeg in the juce to make my lords\n",
      "Nou all thich that wela\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 58.40it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48\tmean(losses):1.683\n",
      "The King said curnen som lay featot them.\n",
      "Make seal not a kibt is grace, and I love\n",
      "Tuves and holy say with haw parn my lord,\n",
      "My tome miseling beaster frummy.\n",
      "\n",
      "LADY BAFDE:\n",
      "That father alver me, her sir, it their hai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 59.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49\tmean(losses):1.679\n",
      "The King said was banith!\n",
      "\n",
      "CLOMENORIO:\n",
      "And as not this wold I holse weel: should drows:\n",
      "And sains bebit of the fruster: strive\n",
      "But you it chance, and not blegnicuponts.\n",
      "\n",
      "HENRY BOLWARCE:\n",
      "What take vincence!\n",
      "\n",
      "KING RIC\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "net = SequenceGenerationNet(vocab_size, 20, 50, num_layers=2, dropout=0.1)\n",
    "net.to(\"cuda:0\")\n",
    "opt = optim.Adam(net.parameters())\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(50):\n",
    "    net.train()\n",
    "    losses = []\n",
    "    for data in tqdm.tqdm(loader):\n",
    "        x = data[:, : -1]\n",
    "        y = data[:, 1:]\n",
    "        x = x.to(\"cuda:0\")\n",
    "        y = y.to(\"cuda:0\")\n",
    "        \n",
    "        y_pred, _ = net(x)\n",
    "        loss = loss_f(y_pred.view(-1, vocab_size), y.view(-1))\n",
    "        net.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "    print(\"epoch:{}\\tmean(losses):{:.3f}\".format(epoch, mean(losses)))\n",
    "    with torch.no_grad():\n",
    "        print(generate_seq(net, device=\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-Decoderモデルによる機械翻訳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "import itertools\n",
    "\n",
    "remove_marks_regex = re.compile(\"[\\,\\(\\)\\[\\]\\*:;¿¡]|<.*?>\")\n",
    "shift_marks_regex = re.compile(\"([?!\\.])\")\n",
    "\n",
    "unk = 0\n",
    "sos = 1\n",
    "eos = 2\n",
    "\n",
    "def normalize(text):\n",
    "    text = text.lower()\n",
    "    text = remove_marks_regex.sub(\"\", text)\n",
    "    text = shift_marks_regex.sub(r\" \\1 \", text)\n",
    "    return text\n",
    "    \n",
    "def parse_line(line):\n",
    "    line = normalize(line.strip())\n",
    "    src, trg, othor = line.split(\"\\t\")\n",
    "    src_tokens = src.strip().split()\n",
    "    trg_tokens = trg.strip().split()\n",
    "    return src_tokens, trg_tokens\n",
    "\n",
    "def build_vocab(tokens):\n",
    "    counts = collections.Counter(tokens)\n",
    "    sorted_counts = sorted(counts.items(), key=lambda c: c[1], reverse=True)\n",
    "    word_list = [\"<UNK>\", \"<SOS>\", \"<EOS>\"] + [x[0] for x in sorted_counts]\n",
    "    word_dict = dict((w, i) for i, w in enumerate(word_list))\n",
    "    return word_list, word_dict\n",
    "\n",
    "def words2tensor(words, word_dict, max_len, padding=0):\n",
    "    words = words + [\"<EOS>\"]\n",
    "    words = [word_dict.get(w, 0) for w in words]\n",
    "    seq_len = len(words)\n",
    "    if seq_len < max_len + 1:\n",
    "        words = words + [padding] * (max_len + 1 - seq_len)\n",
    "    return torch.tensor(words,dtype=torch.int64), seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationPairDataset(Dataset):\n",
    "    def __init__(self, path, max_len=15):\n",
    "        def filter_pair(p):\n",
    "            return not (len(p[0]) > max_len or len(p[1]) > max_len)\n",
    "        \n",
    "        with open(path) as fp:\n",
    "            pairs = map(parse_line, fp)\n",
    "            pairs = filter(filter_pair, pairs)\n",
    "            pairs = list(pairs)\n",
    "        '''\n",
    "        pairs = []\n",
    "        with open(path) as fp:\n",
    "            lines = fp.readlines()\n",
    "            for line in lines:\n",
    "                pair = map(parse_line, line)\n",
    "                pair = filter(filter_pair, pair)\n",
    "                pairs.append(list(pair))\n",
    "        '''\n",
    "        src = [p[0] for p in pairs]\n",
    "        trg = [p[1] for p in pairs]\n",
    "        self.src_word_list, self.src_word_dict = \\\n",
    "            build_vocab(itertools.chain.from_iterable(src))\n",
    "        self.trg_word_list, self.trg_word_dict = \\\n",
    "            build_vocab(itertools.chain.from_iterable(trg))\n",
    "        self.src_data = [words2tensor(words, self.src_word_dict, max_len)\n",
    "                         for words in src]\n",
    "        self.trg_data = [words2tensor(words, self.trg_word_dict, max_len, -100)\n",
    "                         for words in trg]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.src_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        src, lsrc = self.src_data[idx]\n",
    "        trg, ltrg = self.trg_data[idx]\n",
    "        return src, lsrc, trg, ltrg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "max_len = 10\n",
    "path = \"./data/spa-eng/spa.txt\"\n",
    "ds = TranslationPairDataset(path, max_len=max_len)\n",
    "loader = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_size=50,\n",
    "                 num_layers=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_embeddings, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers,\n",
    "                            batch_first=True, dropout=dropout)\n",
    "        \n",
    "    def forward(self, x, h0=None, l=None):\n",
    "        x = self.emb(x)\n",
    "        if l is not None:\n",
    "            x = nn.utils.rnn.pack_padded_sequence(x, l, batch_first=True)\n",
    "        _, h = self.lstm(x, h0)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim=50, hidden_size=50,\n",
    "                 num_layers=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_embeddings, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers,\n",
    "                            batch_first=True, dropout=dropout)\n",
    "        self.linear = nn.Linear(hidden_size, num_embeddings)\n",
    "        \n",
    "    def forward(self, x, h, l=None):\n",
    "        x = self.emb(x)\n",
    "        if l is not None:\n",
    "            x = nn.utils.rnn.pack_padded_sequence(x, l, batch_first=True)\n",
    "        x, h = self.lstm(x, h)\n",
    "        if l is not None:\n",
    "            x = nn.utils.rnn.pad_packed_sequence(\n",
    "                x, batch_first=True, padding_value=0)[0]\n",
    "        x = self.linear(x)\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_str, enc, dec, max_len=15, device=\"cpu\"):\n",
    "    words = normalize(input_str).split()\n",
    "    input_tensor, seq_len = words2tensor(words, ds.src_word_dict,\n",
    "                                         max_len=max_len)\n",
    "    input_tensor = input_tensor.unsqueeze(0)\n",
    "    seq_len = [seq_len]\n",
    "    sos_inputs = torch.tensor(sos, dtype=torch.int64)\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    sos_inputs = sos_inputs.to(device)\n",
    "    \n",
    "    ctx = enc(input_tensor, l=seq_len)\n",
    "    z = sos_inputs\n",
    "    h = ctx\n",
    "    results = []\n",
    "    for i in range(max_len):\n",
    "        o, h = dec(z.view(1, 1), h)\n",
    "        wi = o.detach().view(-1).max(0)[1]\n",
    "        if wi.item() == eos:\n",
    "            break\n",
    "        results.append(wi.item())\n",
    "        z = wi\n",
    "    return \" \".join(ds.trg_word_list[i] for i in results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pulpo pulpo caliéntese ubicaron ubicaron ubicaron ubicaron rescatado rescatado caminamos defendí carcajadas malgastado alegres alegres'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = Encoder(len(ds.src_word_list), 100, 100, 2)\n",
    "dec = Decoder(len(ds.trg_word_list), 100, 100, 2)\n",
    "translate(\"I am a student.\", enc, dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.to(\"cuda:0\")\n",
    "dec.to(\"cuda:0\")\n",
    "opt_enc = optim.Adam(enc.parameters(), 0.002)\n",
    "opt_dec = optim.Adam(dec.parameters(), 0.002)\n",
    "loss_f = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:32<00:00, 51.88it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.3914137713763175\n",
      "un gran .\n",
      "que tom se se se se se se se se\n",
      "mi padre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:31<00:00, 52.19it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3.38359257181724\n",
      "un gran .\n",
      "que tom se se se se se quedó .\n",
      "mi padre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:31<00:00, 52.38it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2.1486862899304007\n",
      "un estudiante .\n",
      "a tom .\n",
      "mi nombre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:32<00:00, 51.92it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1.6488154805293318\n",
      "un estudiante .\n",
      "tom .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:32<00:00, 51.85it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1.4034806683498557\n",
      "un estudiante .\n",
      "como bailar .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:32<00:00, 51.56it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 1.2369211019158792\n",
      "un estudiante .\n",
      "tom como comer .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:32<00:00, 51.63it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 1.108269841194439\n",
      "un estudiante .\n",
      "como comer .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:32<00:00, 52.03it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 1.008827165073278\n",
      "un estudiante .\n",
      "como comer .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:32<00:00, 52.05it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.9271537867628512\n",
      "un estudiante .\n",
      "como mary .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:31<00:00, 52.40it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.8612521870010326\n",
      "un estudiante .\n",
      "como comer .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:32<00:00, 51.98it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.805917329719516\n",
      "ser estudiante .\n",
      "como comer estúpido .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:32<00:00, 51.87it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.7603191016387253\n",
      "ser estudiante .\n",
      "como comer estúpido .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:31<00:00, 53.61it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 0.7203978111012643\n",
      "un estudiante .\n",
      "como practicar estúpido .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:31<00:00, 52.66it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0.6858058252326008\n",
      "un estudiante .\n",
      "como comer .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:31<00:00, 52.59it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 0.656260742896459\n",
      "ser estudiante .\n",
      "como comer estúpido .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:31<00:00, 52.24it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.6294121833301248\n",
      "ser estudiante .\n",
      "como comer estúpido .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:30<00:00, 53.96it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0.6056016509880682\n",
      "un estudiante .\n",
      "comer como carne .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:31<00:00, 52.99it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 0.5843026137688294\n",
      "ser estudiante .\n",
      "como comer .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:31<00:00, 52.98it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 0.5659981964587593\n",
      "ser estudiante .\n",
      "como comer estúpido .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:31<00:00, 53.12it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0.5471558037961947\n",
      "ser un estudiante .\n",
      "como comer estúpido .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:31<00:00, 52.83it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.53202794045031\n",
      "un estudiante .\n",
      "como comer pizza .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:31<00:00, 52.66it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 0.5172774225187187\n",
      "ser un estudiante .\n",
      "comer como él .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:30<00:00, 53.79it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 0.5038751446220483\n",
      "ser estudiante .\n",
      "comer como jackson .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:30<00:00, 54.26it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 0.4920305671418557\n",
      "ser un estudiante .\n",
      "comer como come .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:31<00:00, 53.44it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 0.47908452176460986\n",
      "ser estudiante .\n",
      "comer como come .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:31<00:00, 52.38it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 0.46872306137489955\n",
      ".\n",
      "comer como tú .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:32<00:00, 52.01it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 0.45927732143582417\n",
      ".\n",
      "comer como jackson .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:31<00:00, 52.29it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 0.44919021558217787\n",
      ".\n",
      "comer como el tonto .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:31<00:00, 53.22it/s]\n",
      "  0%|          | 0/1666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 0.4406930407484611\n",
      ".\n",
      "comer como un tonto .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:31<00:00, 53.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 0.4322027559755515\n",
      ".\n",
      "comer como un tonto .\n",
      "mi madre .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def to2D(x):\n",
    "    shapes = x.shape\n",
    "    return x.reshape(shapes[0] * shapes[1], -1)\n",
    "\n",
    "for epoch in range(30):\n",
    "    enc.train(), dec.train()\n",
    "    losses = []\n",
    "    for x, lx, y, ly in tqdm.tqdm(loader):\n",
    "        lx, sort_idx = lx.sort(descending=True)\n",
    "        x, y, ly = x[sort_idx], y[sort_idx], ly[sort_idx]\n",
    "        x, y = x.to(\"cuda:0\"), y.to(\"cuda:0\")\n",
    "        ctx = enc(x, l=lx)\n",
    "        \n",
    "        ly, sort_idx = ly.sort(descending=True)\n",
    "        y = y[sort_idx]\n",
    "        h0 = (ctx[0][:, sort_idx, :], ctx[1][:, sort_idx, :])\n",
    "        z = y[:, :-1].detach()\n",
    "        z[z==-100] = 0\n",
    "        \n",
    "        o, _ = dec(z, h0, l=ly-1)\n",
    "        loss = loss_f(to2D(o[:]), to2D(y[:, 1:max(ly)]).squeeze())\n",
    "        enc.zero_grad(), dec.zero_grad()\n",
    "        loss.backward()\n",
    "        opt_enc.step(), opt_dec.step()\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "    enc.eval(), dec.eval()\n",
    "    print(epoch, mean(losses))\n",
    "    with torch.no_grad():\n",
    "        print(translate(\"I am a student.\",\n",
    "                        enc, dec, max_len=max_len, device=\"cuda:0\"))\n",
    "        print(translate(\"He likes to eat pizza.\",\n",
    "                        enc, dec, max_len=max_len, device=\"cuda:0\"))\n",
    "        print(translate(\"She is my mother.\",\n",
    "                        enc, dec, max_len=max_len, device=\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
